{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f6c01df",
   "metadata": {},
   "source": [
    "Load the pre trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47193ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastModel\n",
    "from transformers import AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tokenizers/tokenizer\") #change this to the path of the tokenizer\n",
    "\n",
    "model, _ = FastModel.from_pretrained(\n",
    "    \"trained_models/model\", #change this to the path of the model\n",
    "    max_seq_length=config[\"max_seq_length\"],\n",
    "    load_in_4bit=True,  # Must match training quantization\n",
    "    resize_model_vocab=len(tokenizer),\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "#use model for inference\n",
    "model = FastModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b8fbef",
   "metadata": {},
   "source": [
    "Get the validation dataset so it is possible to calculate the K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc7dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"max_seq_length\": 128,\n",
    "    \"batch_size\": 128,\n",
    "    \"valid_ratio\": 0.2,\n",
    "    \"dataset_path\": \"datasets/5k_hdfs_train.txt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94951562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"text\", data_files=config[\"dataset_path\"])\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=config[\"valid_ratio\"], shuffle=False, seed=42)\n",
    "\n",
    "def sliding_window_tokenize(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=config[\"max_seq_length\"])\n",
    "\n",
    "valid_tokenized_dataset = dataset[\"test\"].map(\n",
    "    sliding_window_tokenize,\n",
    "    batched=True,\n",
    "    batch_size = config[\"batch_size\"],\n",
    "    remove_columns=[\"text\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9d4121",
   "metadata": {},
   "source": [
    "Get the k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257ef5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "def calculate_multiple_topk_miss_rates(sequence, topk_candidates):\n",
    "    model.eval()\n",
    "    device = model.device\n",
    "\n",
    "    miss_rates_by_k = {k: [] for k in topk_candidates}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(sequence), desc=f\"Evaluation\", unit=\"sequence\") as pbar:\n",
    "            for seq_idx, token_list in enumerate(sequence):\n",
    "                token_tensor = torch.tensor(token_list, dtype=torch.long, device=device).unsqueeze(0)\n",
    "                input_ids = token_tensor[:, :-1]\n",
    "                labels = token_tensor[:, 1:]\n",
    "\n",
    "                if input_ids.size(1) == 0:\n",
    "                    for k in topk_candidates:\n",
    "                        miss_rates_by_k[k].append(1.0)\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "\n",
    "                with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                    outputs = model(input_ids=input_ids)\n",
    "\n",
    "                logits = outputs.logits.to(torch.float32)\n",
    "\n",
    "                total_tokens_to_predict = labels.size(1)\n",
    "\n",
    "                if total_tokens_to_predict <= 2:\n",
    "                    for k in topk_candidates:\n",
    "                        miss_rates_by_k[k].append(0.0)\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "\n",
    "\n",
    "                max_k = max(topk_candidates)\n",
    "                _, topk_predictions = torch.topk(logits, k=max_k, dim=-1)\n",
    "\n",
    "                for k in topk_candidates:\n",
    "                    correct = 0\n",
    "                    for i in range(total_tokens_to_predict):\n",
    "                        true_token_id = labels[0, i].item()\n",
    "                        predicted_k_token_ids = topk_predictions[0, i, :k].tolist()\n",
    "                        if true_token_id in predicted_k_token_ids:\n",
    "                            correct += 1\n",
    "                    miss_rate = 1.0 - (correct / total_tokens_to_predict)\n",
    "                    miss_rate = 0.01 if (0 < miss_rate < 0.01) else miss_rate\n",
    "                    miss_rates_by_k[k].append(miss_rate)\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "    return {k: np.array(miss_rates) for k, miss_rates in miss_rates_by_k.items()}\n",
    "\n",
    "\n",
    "topk_candidates = list(range(1, 20)) #change this to a range that fits your dataset\n",
    "miss_rates_dict = calculate_multiple_topk_miss_rates(valid_tokenized_dataset[\"input_ids\"], topk_candidates)\n",
    "\n",
    "for k, miss_rates in miss_rates_dict.items():\n",
    "    print(f\"Top-{k} avg miss rate: {miss_rates.mean():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
