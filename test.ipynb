{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "906b8bed",
   "metadata": {},
   "source": [
    "Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c8564",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"max_seq_length\": 128,\n",
    "    \"batch_size\": 128,\n",
    "    \"model_dir\": \"drive/MyDrive/final\",\n",
    "    \"tokenizer_dir\": \"drive/MyDrive/final\",\n",
    "    \"test_normal\": \"datasets/5k_bgl_normal.txt\",\n",
    "    \"test_abnormal\": \"datasets/5k_bgl_abnormal.txt\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d927150",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e9629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastModel\n",
    "from transformers import AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "tokenizer = AutoTokenizer.from_pretrained(config[\"tokenizer_dir\"])\n",
    "\n",
    "model, _ = FastModel.from_pretrained(\n",
    "    config[\"model_dir\"],\n",
    "    max_seq_length=config[\"max_seq_length\"],\n",
    "    load_in_4bit=True,  \n",
    "    resize_model_vocab=len(tokenizer),\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "    \n",
    "    \n",
    "model = FastModel.for_inference(model)\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905eb4d7",
   "metadata": {},
   "source": [
    "Tokenize the testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a183a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_normal = load_dataset(\"text\", data_files=config[\"test_normal\"])\n",
    "dataset_abnormal = load_dataset(\"text\", data_files=config[\"test_abnormal\"])\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=config[\"max_seq_length\"])\n",
    "\n",
    "tokenized_dataset_normal = dataset_normal.map(tokenize_function, batched=True, batch_size=config[\"batch_size\"], remove_columns=[\"text\"])\n",
    "tokenized_dataset_abnormal = dataset_abnormal.map(tokenize_function, batched=True, batch_size=config[\"batch_size\"], remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc4d2c9",
   "metadata": {},
   "source": [
    "Calculate the misses from the testing sequences (PS: Change the K to the one obtained in the get_k file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948be514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_topk_miss_rate_optimized(sequences, model, tokenizer, top_k=10, batch_size=256):\n",
    "    device = model.device\n",
    "    model.eval()\n",
    "    all_miss_rates = []\n",
    "\n",
    "    pad_token_id = tokenizer.pad_token_id or tokenizer.eos_token_id\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(sequences), batch_size), desc=f\"Top-{top_k} Miss Rate\"):\n",
    "            batch_seqs = sequences[i:i + batch_size]\n",
    "            batch_tensors = [torch.tensor(seq, dtype=torch.long) for seq in batch_seqs]\n",
    "\n",
    "            valid_indices = [idx for idx, t in enumerate(batch_tensors) if len(t) > 2]\n",
    "            if not valid_indices:\n",
    "                all_miss_rates.extend([0.0] * len(batch_tensors))\n",
    "                continue\n",
    "\n",
    "            batch_tensors = [batch_tensors[idx] for idx in valid_indices]\n",
    "\n",
    "            input_ids = [t[:-1] for t in batch_tensors]\n",
    "            labels = [t[1:] for t in batch_tensors]\n",
    "\n",
    "            input_ids = pad_sequence(input_ids, batch_first=True, padding_value=pad_token_id).to(device)\n",
    "            labels = pad_sequence(labels, batch_first=True, padding_value=-100).to(device)\n",
    "            attention_mask = (input_ids != pad_token_id).long()\n",
    "\n",
    "            with torch.amp.autocast(device_type=device.type, dtype=torch.float16 if device.type == 'cuda' else torch.float32):\n",
    "                logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "\n",
    "            logits = logits.to(torch.float32)\n",
    "\n",
    "            if tokenizer.unk_token_id is not None:\n",
    "                logits[:, :, tokenizer.unk_token_id] = float('-inf')\n",
    "\n",
    "            actual_k = min(top_k, logits.size(-1))\n",
    "            topk_preds = torch.topk(logits, k=actual_k, dim=-1).indices  # [B, L, K]\n",
    "\n",
    "            labels_exp = labels.unsqueeze(-1)  # [B, L, 1]\n",
    "            correct = (topk_preds == labels_exp).any(dim=-1)  # [B, L]\n",
    "            valid = labels != -100\n",
    "\n",
    "            hits = (correct & valid).sum(dim=1)\n",
    "            total = valid.sum(dim=1)\n",
    "            miss_rate = 1.0 - (hits.float() / total.float())\n",
    "            miss_rate = torch.where((miss_rate < 0.01) & (miss_rate > 0), torch.tensor(1, device=device), miss_rate)\n",
    "\n",
    "            result = [0.0] * len(batch_seqs)\n",
    "            for j, idx in enumerate(valid_indices):\n",
    "                result[idx] = miss_rate[j].item()\n",
    "            \n",
    "            all_miss_rates.extend(result)\n",
    "\n",
    "    return np.array(all_miss_rates)\n",
    "\n",
    "\n",
    "normal_perplexities = calculate_topk_miss_rate_optimized(tokenized_dataset_normal[\"train\"][\"input_ids\"], model, tokenizer, top_k=177) #change the k to the one calculated in the training\n",
    "abnormal_perplexities = calculate_topk_miss_rate_optimized(tokenized_dataset_abnormal[\"train\"][\"input_ids\"], model, tokenizer, top_k=177) #change the k to the one calculated in the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a04960d",
   "metadata": {},
   "source": [
    "Calculate restuls (every sequence with a miss are all considered anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a319764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "all_perplexities = np.concatenate([normal_perplexities, abnormal_perplexities])\n",
    "\n",
    "normal_labels = np.zeros(len(normal_perplexities), dtype=int)  # 0 for normal\n",
    "abnormal_labels = np.ones(len(abnormal_perplexities), dtype=int)  # 1 for abnormal\n",
    "y_true = np.concatenate([normal_labels, abnormal_labels])\n",
    "\n",
    "threshold = 0.01\n",
    "y_pred_fixed = (all_perplexities >= threshold).astype(int)\n",
    "precision_fixed = precision_score(y_true, y_pred_fixed)\n",
    "recall_fixed = recall_score(y_true, y_pred_fixed)\n",
    "f1_fixed = f1_score(y_true, y_pred_fixed)\n",
    "\n",
    "print(f\"Fixed Threshold: {threshold:.2f}\")\n",
    "print(f\"Precision: {precision_fixed:.4f}\")\n",
    "print(f\"Recall: {recall_fixed:.4f}\")\n",
    "print(f\"F1-Score: {f1_fixed:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
